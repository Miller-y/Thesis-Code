import numpy as np
import os
import torch
from torch import nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import scipy.io as sio
from scipy import signal
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import torch.optim.lr_scheduler as lr_scheduler
import pandas as pd

# ---------------------- æ•°æ®é›†å®šä¹‰ ----------------------
class CSIDataset(Dataset):
    def __init__(self, mat_file_path, csi_scaler=None, position_scaler=None):
        mat_data = sio.loadmat(mat_file_path)
        csi_data = mat_data['data'] # é¢„æœŸå½¢çŠ¶: (1620, 8, 108, 60) æˆ–ç±»ä¼¼
        position_data = mat_data['position']

        # ç¡®ä¿æ•°æ®ä¸º float32
        csi_data = csi_data.astype(np.float32)

        # ç»´åº¦è°ƒæ•´é€»è¾‘
        # è‡ªåŠ¨é€‚åº”ä¸åŒçš„å¤©çº¿æ•°é‡å’Œå­è½½æ³¢æ•°é‡
        if csi_data.ndim == 4:
            # å‡è®¾ç»´åº¦é¡ºåºä¸º (N, C, H, W)
            self.csi_data = csi_data
        elif csi_data.ndim == 3:
             # å¦‚æœæ˜¯ (N, H, C) è¿™ç§å°‘è§æƒ…å†µï¼Œå¯ä»¥åœ¨è¿™é‡Œå¤„ç†ï¼Œæš‚ä¸”å‡è®¾è¾“å…¥è§„èŒƒ
             pass
        else:
            # å°è¯•å…¼å®¹æ—§é€»è¾‘ï¼Œä½†ä¸å¼ºåˆ¶æŠ¥é”™
            # raise ValueError(f"CSIæ•°æ®ç»´åº¦ä¸ç¬¦åˆé¢„æœŸ: {csi_data.shape}")
            self.csi_data = csi_data

        # é¢„å¤„ç†ï¼šå»å™ª
        self.csi_data = self.apply_filter(self.csi_data, cutoff=20, fs=100)

        # å½’ä¸€åŒ–å¤„ç†
        # 1. CSI æ•°æ®å½’ä¸€åŒ–
        N, C, H, W = self.csi_data.shape
        csi_data_flat = self.csi_data.reshape(-1, 1)

        if csi_scaler is None:
            self.csi_scaler = MinMaxScaler()
            csi_data_normalized = self.csi_scaler.fit_transform(csi_data_flat).reshape(N, C, H, W)
        else:
            self.csi_scaler = csi_scaler
            csi_data_normalized = self.csi_scaler.transform(csi_data_flat).reshape(N, C, H, W)

        self.csi_data = torch.tensor(csi_data_normalized, dtype=torch.float32)

        # 2. ä½ç½®æ•°æ®å½’ä¸€åŒ–
        if position_scaler is None:
            self.position_scaler = MinMaxScaler()
            self.positions = torch.tensor(
                self.position_scaler.fit_transform(position_data),
                dtype=torch.float32
            )
        else:
            self.position_scaler = position_scaler
            self.positions = torch.tensor(
                self.position_scaler.transform(position_data),
                dtype=torch.float32
            )

        if len(self.csi_data) != len(self.positions):
            raise ValueError("CSIæ•°æ®ä¸ä½ç½®æ•°æ®æ•°é‡ä¸åŒ¹é…")

    def apply_filter(self, data, order=6, cutoff=5, fs=100):
        # å¯¹æœ€åä¸€ä¸ªç»´åº¦ï¼ˆæ—¶é—´ï¼‰è¿›è¡Œæ»¤æ³¢
        # cutoff / (0.5 * fs) æ˜¯å½’ä¸€åŒ–æˆªæ­¢é¢‘ç‡
        nyquist = 0.5 * fs
        if cutoff >= nyquist:
             cutoff = nyquist - 0.1 # é˜²æ­¢æŠ¥é”™
        b, a = signal.butter(order, cutoff / nyquist, btype='low')
        return signal.filtfilt(b, a, data, axis=-1)

    def __len__(self):
        return len(self.csi_data)

    def __getitem__(self, idx):
        return self.csi_data[idx], self.positions[idx]

# ---------------------- å¤šå°ºåº¦æ—¶åºå·ç§¯ (MSTC) ----------------------
class MSTC(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_sizes=(3, 9, 15, 25)):
        super(MSTC, self).__init__()
        # å¹¶è¡Œå››ä¸ªå·ç§¯åˆ†æ”¯ï¼Œé»˜è®¤æ ¸å¤§å°åˆ†åˆ«ä¸º 1Ã—3ã€1Ã—9ã€1Ã—15ã€1Ã—25
        # å…è®¸é€šè¿‡ kernel_sizes å‚æ•°è‡ªå®šä¹‰æ ¸å¤§å°
        branch_channels = out_channels // 4

        p = [(k - 1) // 2 for k in kernel_sizes]

        self.branch1 = nn.Conv2d(in_channels, branch_channels, kernel_size=(1, kernel_sizes[0]), padding=(0, p[0]))
        self.branch2 = nn.Conv2d(in_channels, branch_channels, kernel_size=(1, kernel_sizes[1]), padding=(0, p[1]))
        self.branch3 = nn.Conv2d(in_channels, branch_channels, kernel_size=(1, kernel_sizes[2]), padding=(0, p[2]))
        self.branch4 = nn.Conv2d(in_channels, branch_channels, kernel_size=(1, kernel_sizes[3]), padding=(0, p[3]))

        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        x1 = self.branch1(x)
        x2 = self.branch2(x)
        x3 = self.branch3(x)
        x4 = self.branch4(x)

        out = torch.cat([x1, x2, x3, x4], dim=1)
        out = self.bn(out)
        out = self.relu(out)
        return out

# ---------------------- æ·±åº¦æ®‹å·®å— (DRB) -> å‡çº§ä¸º ConvNeXt Block ----------------------
class LayerNorm(nn.Module):
    r""" LayerNorm that supports two data formats: channels_last (default) or channels_first.
    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with
    shape (batch_size, height, width, channels) while channels_first corresponds to inputs
    with shape (batch_size, channels, height, width).
    """
    def __init__(self, normalized_shape, eps=1e-6, data_format="channels_last"):
        super().__init__()
        self.weight = nn.Parameter(torch.ones(normalized_shape))
        self.bias = nn.Parameter(torch.zeros(normalized_shape))
        self.eps = eps
        self.data_format = data_format
        if self.data_format not in ["channels_last", "channels_first"]:
            raise NotImplementedError
        self.normalized_shape = (normalized_shape, )

    def forward(self, x):
        if self.data_format == "channels_last":
            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)
        elif self.data_format == "channels_first":
            u = x.mean(1, keepdim=True)
            s = (x - u).pow(2).mean(1, keepdim=True)
            x = (x - u) / torch.sqrt(s + self.eps)
            x = self.weight[:, None, None] * x + self.bias[:, None, None]
            return x

class ConvNeXtBlock(nn.Module):
    r""" ConvNeXt Block. There are two equivalent implementations:
    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)
    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back
    We use (2) as we find it slightly faster in PyTorch

    Args:
        dim (int): Number of input channels.
        drop_path (float): Stochastic depth rate. Default: 0.0
        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.
    """
    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):
        super().__init__()
        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv
        self.norm = LayerNorm(dim, eps=1e-6)
        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers
        self.act = nn.GELU()
        self.pwconv2 = nn.Linear(4 * dim, dim)
        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)),
                                    requires_grad=True) if layer_scale_init_value > 0 else None
        self.drop_path = nn.Identity() # Simplified for this use case

    def forward(self, x):
        input = x
        x = self.dwconv(x)
        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)
        x = self.norm(x)
        x = self.pwconv1(x)
        x = self.act(x)
        x = self.pwconv2(x)
        if self.gamma is not None:
            x = self.gamma * x
        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)

        x = input + self.drop_path(x)
        return x

# ---------------------- å¢å¼ºé€šé“æ³¨æ„åŠ› (ECA) ----------------------
class ECA(nn.Module):
    def __init__(self, channels, reduction=16):
        super(ECA, self).__init__()
        self.mlp = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        b, c, _, _ = x.size()
        avg_pool = F.adaptive_avg_pool2d(x, 1).view(b, c)
        max_pool = F.adaptive_max_pool2d(x, 1).view(b, c)
        std_pool = torch.std(x.view(b, c, -1), dim=2)

        y_avg = self.mlp(avg_pool)
        y_max = self.mlp(max_pool)
        y_std = self.mlp(std_pool)

        y = y_avg + y_max + y_std
        scale = self.sigmoid(y).view(b, c, 1, 1)
        return x * scale

# ---------------------- å¢å¼ºç©ºé—´æ³¨æ„åŠ› (ESA) -> å‡çº§ä¸º Coordinate Attention ----------------------
class CoordAtt(nn.Module):
    def __init__(self, inp, oup, reduction=32):
        super(CoordAtt, self).__init__()
        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))
        self.pool_w = nn.AdaptiveAvgPool2d((1, None))

        mip = max(8, inp // reduction)

        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)
        self.bn1 = nn.BatchNorm2d(mip)
        self.act = nn.Hardswish()

        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)
        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)


    def forward(self, x):
        identity = x

        n,c,h,w = x.size()
        x_h = self.pool_h(x)
        x_w = self.pool_w(x).permute(0, 1, 3, 2)

        y = torch.cat([x_h, x_w], dim=2)
        y = self.conv1(y)
        y = self.bn1(y)
        y = self.act(y)

        x_h, x_w = torch.split(y, [h, w], dim=2)
        x_w = x_w.permute(0, 1, 3, 2)

        a_h = self.conv_h(x_h).sigmoid()
        a_w = self.conv_w(x_w).sigmoid()

        out = identity * a_h * a_w
        return out

# ---------------------- æ··åˆæŸå¤±å‡½æ•° (Position + Smoothing) ----------------------
class CustomLoss(nn.Module):
    def __init__(self, beta=1.0, eta1=1.0, eta2=0.5):
        super(CustomLoss, self).__init__()
        self.beta = beta
        self.eta1 = eta1
        self.eta2 = eta2
        # Lp: ä½¿ç”¨ PyTorch å†…ç½®çš„ SmoothL1Lossï¼Œå®ƒåœ¨ |x|<beta æ—¶æ˜¯ 0.5*x^2/betaï¼Œå¦åˆ™æ˜¯ |x|-0.5*beta
        # è¿™ä¸å›¾ç‰‡ä¸­çš„å…¬å¼ç²¾ç¥ä¸€è‡´ï¼ˆé²æ£’å›å½’ï¼‰ï¼Œä¸”æ•°å€¼æ›´ç¨³å®š
        self.position_loss = nn.SmoothL1Loss(beta=beta, reduction='mean')

    def forward(self, pred, target):
        # 1. ä½ç½®æŸå¤± (Lp)
        l_p = self.position_loss(pred, target)

        # 2. å¹³æ»‘æŸå¤± (Ls)
        # è®¡ç®—ç›¸é‚»æ—¶é—´æ­¥çš„å·®åˆ†å‘é‡ (Velocity/Step vector)
        # æ³¨æ„ï¼šè¿™è¦æ±‚ Batch ä¸­çš„æ•°æ®æ˜¯æŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„
        diff_pred = pred[1:] - pred[:-1]
        diff_target = target[1:] - target[:-1]

        # è®¡ç®—å·®åˆ†å‘é‡ä¹‹é—´çš„æ¬§æ°è·ç¦» (L2 norm)
        # Ls = mean( || (p_i - p_{i-1}) - (t_i - t_{i-1}) ||_2 )
        if diff_pred.shape[0] > 0:
            l_s = torch.mean(torch.norm(diff_pred - diff_target, p=2, dim=1))
        else:
            l_s = torch.tensor(0.0, device=pred.device)

        # æ€»æŸå¤±
        loss = self.eta1 * l_p + self.eta2 * l_s
        return loss

# ---------------------- MSRANet æ¨¡å‹ (å‡çº§ç‰ˆ) ----------------------
class MSRANet(nn.Module):
    def __init__(self, in_channels=8, out_dim=2):
        super(MSRANet, self).__init__()

        # 1. ç‰¹å¾æå–æ¨¡å—
        # è¾“å…¥é€šé“æ”¹ä¸ºåŠ¨æ€ä¼ å…¥ (é€‚é… 3 å¤©çº¿æˆ– 8 å¤©çº¿)
        self.stage1 = nn.Sequential(
            MSTC(in_channels, 64),
            ConvNeXtBlock(64),
            nn.AvgPool2d(2)
        )

        self.stage2 = nn.Sequential(
            MSTC(64, 128),
            ConvNeXtBlock(128),
            nn.AvgPool2d(2)
        )

        self.stage3 = nn.Sequential(
            # æ·±å±‚ç‰¹å¾çš„æ—¶é—´ç»´åº¦è¾ƒå°ï¼Œå‡å°å·ç§¯æ ¸å°ºå¯¸ä»¥é¿å…æ— æ•ˆè®¡ç®—
            MSTC(128, 256, kernel_sizes=(3, 5, 7, 9)),
            ConvNeXtBlock(256),
            nn.AvgPool2d(2)
        )

        # 2. åŒé‡å¢å¼ºæ³¨æ„åŠ›æœºåˆ¶ (ECA + CoordAtt)
        self.attention = nn.Sequential(
            ECA(256),
            CoordAtt(256, 256)
        )

        # 3. è¾“å‡ºå±‚ (3Dåæ ‡) -> ä¿®æ”¹ä¸º 2D åæ ‡
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.6),
            nn.Linear(128, out_dim) # è¾“å‡ºç»´åº¦åŠ¨æ€è°ƒæ•´ (2D/3D)
        )

    def forward(self, x):
        x = self.stage1(x)
        x = self.stage2(x)
        x = self.stage3(x)

        x = self.attention(x)

        x = self.avgpool(x)
        x = self.classifier(x)
        return x

# ---------------------- è¾“å‡ºå¹³æ»‘æ¨¡å— (WMA) ----------------------
class WeightedMovingAverage:
    def __init__(self, window_size=5):
        self.window_size = window_size
        self.history = []

    def update(self, new_point):
        self.history.append(new_point)
        if len(self.history) > self.window_size:
            self.history.pop(0)

        weights = np.arange(1, len(self.history) + 1)
        weights = weights / weights.sum()

        weighted_sum = np.zeros_like(new_point)
        for i, point in enumerate(self.history):
            weighted_sum += point * weights[i]

        return weighted_sum

    def smooth_sequence(self, sequence):
        smoothed = []
        self.history = []
        for point in sequence:
            smoothed.append(self.update(point))
        return np.array(smoothed)

# ---------------------- è®­ç»ƒå‡½æ•° ----------------------
def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs, device):
    model.train()
    loss_history = {'train': [], 'test': []}

    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        loss_history['train'].append(epoch_loss / len(train_loader))

        model.eval()
        test_loss = 0.0
        with torch.no_grad():
            for inputs, targets in test_loader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                test_loss += criterion(outputs, targets).item()
        loss_history['test'].append(test_loss / len(test_loader))

        scheduler.step(loss_history['test'][-1])
        print(f"Epoch {epoch + 1}/{epochs} | Train Loss: {loss_history['train'][-1]:.4f} | Test Loss: {loss_history['test'][-1]:.4f}")

    return loss_history

# ---------------------- è¯„ä¼°å‡½æ•° ----------------------
def evaluate_model(model, data_loader, scaler, device):
    model.eval()
    predictions = []
    true_positions = []
    with torch.no_grad():
        for inputs, targets in data_loader:
            inputs = inputs.to(device)
            outputs = model(inputs).cpu().numpy()
            predictions.append(outputs)
            true_positions.append(targets.numpy())

    predictions = np.concatenate(predictions, axis=0)
    true_positions = np.concatenate(true_positions, axis=0)
    predictions = scaler.inverse_transform(predictions)
    true_positions = scaler.inverse_transform(true_positions)
    return predictions, true_positions

# ---------------------- å¯è§†åŒ–å‡½æ•° (2D/3D åŠ¨æ€é€‚åº”) ----------------------
def plot_comparison(true, pred, title, xlim=None, ylim=None, zlim=None):
    num_dimensions = true.shape[1]

    if num_dimensions == 3:
        fig = plt.figure(figsize=(12, 8))
        ax = fig.add_subplot(111, projection='3d')

        # ç»˜åˆ¶çœŸå®è½¨è¿¹å’Œé¢„æµ‹è½¨è¿¹
        ax.scatter(true[:, 0], true[:, 1], true[:, 2], c='blue', label='çœŸå®ä½ç½®', alpha=0.6, s=20)
        ax.scatter(pred[:, 0], pred[:, 1], pred[:, 2], c='red', label='é¢„æµ‹ä½ç½®', alpha=0.6, s=20)

        # ç»˜åˆ¶è¿æ¥çº¿
        for i in range(min(len(true), len(pred))):
            ax.plot([true[i, 0], pred[i, 0]],
                    [true[i, 1], pred[i, 1]],
                    [true[i, 2], pred[i, 2]], 'k--', linewidth=0.5, alpha=0.3)

        ax.set_zlabel('Zåæ ‡')
        if zlim: ax.set_zlim(zlim)

    elif num_dimensions == 2:
        fig, ax = plt.subplots(figsize=(10, 8))

        # ç»˜åˆ¶çœŸå®è½¨è¿¹å’Œé¢„æµ‹è½¨è¿¹
        ax.scatter(true[:, 0], true[:, 1], c='blue', label='çœŸå®ä½ç½®', alpha=0.6, s=20)
        ax.scatter(pred[:, 0], pred[:, 1], c='red', label='é¢„æµ‹ä½ç½®', alpha=0.6, s=20)

        # ç»˜åˆ¶è¿æ¥çº¿
        for i in range(min(len(true), len(pred))):
            ax.plot([true[i, 0], pred[i, 0]],
                    [true[i, 1], pred[i, 1]], 'k--', linewidth=0.5, alpha=0.3)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ç»´åº¦: {num_dimensions}. ä»…æ”¯æŒ 2D æˆ– 3D åæ ‡ã€‚")

    ax.set_title(title)
    ax.set_xlabel('Xåæ ‡')
    ax.set_ylabel('Yåæ ‡')

    if xlim: ax.set_xlim(xlim)
    if ylim: ax.set_ylim(ylim)

    ax.legend()
    plt.grid(True)
    plt.show()

# ---------------------- ç‰¹å¾å›¾å¯è§†åŒ–å‡½æ•° ----------------------
def visualize_feature_maps(model, dataset, device, save_dir='feature_visualization'):
    """
    å¯è§†åŒ–æ¨¡å‹å…³é”®å±‚çš„ç‰¹å¾å›¾
    """
    import os
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    pass  # é˜²æ­¢ç¼©è¿›é”™è¯¯

    # 1. å®šä¹‰ Hook ç”¨äºè·å–ä¸­é—´å±‚è¾“å‡º
    activations = {}
    def get_activation(name):
        def hook(model, input, output):
            activations[name] = output.detach()
        return hook
    
    # 1.5 ç‰¹åˆ«Hookï¼šè·å– MSTC å†…éƒ¨å››ä¸ªåˆ†æ”¯çš„è¾“å‡º
    # æˆ‘ä»¬ä¸ä»…è¦è·å– MSTC çš„æ€»è¾“å‡ºï¼Œè¿˜è¦æ·±å…¥åˆ° stage1[0] (å³ç¬¬ä¸€ä¸ª MSTC æ¨¡å—) å†…éƒ¨
    mstc_branches = {}
    def get_mstc_branch(name):
        def hook(model, input, output):
            mstc_branches[name] = output.detach()
        return hook

    # 1.6 ç‰¹åˆ«Hookï¼šAttention Comparison (Input -> ECA -> CoordAtt)
    att_maps = {}
    def get_att(name):
        def hook(model, input, output):
            att_maps[name] = output.detach()
        return hook

    # 2. æ³¨å†Œ Hooks åˆ°å…³é”®å±‚
    # Attention Hooks
    # Input to Attention (Output of Stage 3)
    h_att_in = model.stage3.register_forward_hook(get_att('Before_Att'))
    # Output of ECA (First module in attention Sequential)
    h_att_eca = model.attention[0].register_forward_hook(get_att('After_ECA'))
    # Output of CoordAtt (Second module in attention Sequential)
    h_att_final = model.attention[1].register_forward_hook(get_att('After_Final'))

    # Stage 1
    # æ³¨å†Œåˆ° MSTC çš„å››ä¸ªåˆ†æ”¯
    h_b1 = model.stage1[0].branch1.register_forward_hook(get_mstc_branch('MSTC_Kernel_3'))
    h_b2 = model.stage1[0].branch2.register_forward_hook(get_mstc_branch('MSTC_Kernel_9'))
    h_b3 = model.stage1[0].branch3.register_forward_hook(get_mstc_branch('MSTC_Kernel_15'))
    h_b4 = model.stage1[0].branch4.register_forward_hook(get_mstc_branch('MSTC_Kernel_25'))

    handle1 = model.stage1[0].register_forward_hook(get_activation('1_Stage1_MSTC'))
    handle2 = model.stage1[1].register_forward_hook(get_activation('2_Stage1_ConvNeXt'))
    # Stage 2
    handle3 = model.stage2[1].register_forward_hook(get_activation('3_Stage2_ConvNeXt'))
    # Stage 3
    handle4 = model.stage3[1].register_forward_hook(get_activation('4_Stage3_ConvNeXt'))
    # Attention
    handle5 = model.attention.register_forward_hook(get_activation('5_After_Attention'))

    # 3. é€‰å–ä¸€ä¸ªæµ‹è¯•æ ·æœ¬
    model.eval()
    # éšæœºé€‰å–ä¸€ä¸ªæ ·æœ¬ï¼Œæˆ–è€…å›ºå®šé€‰ç¬¬ä¸€ä¸ª
    input_tensor, _ = dataset[0] 
    input_tensor = input_tensor.unsqueeze(0).to(device) # (1, C, H, W)

    # 4. å‰å‘ä¼ æ’­ (è§¦å‘ Hooks)
    print(f"æ­£åœ¨ç”Ÿæˆç‰¹å¾å¯è§†åŒ–å›¾ï¼Œä¿å­˜è‡³ {save_dir}/ ...")
    with torch.no_grad():
        _ = model(input_tensor)

    # 5. ç»˜å›¾å¹¶ä¿å­˜
    import matplotlib.pyplot as plt
    
    # === 3. ä¿å­˜ Input Raw å›¾ (æœ€ä¸ºåŸå§‹çš„å¯¹æ¯”) ===
    # input_tensor shape: (1, C, H, W)
    raw_data = input_tensor.squeeze(0).cpu()
    # è®¡ç®— Channel Mean ä½œä¸ºçƒ­åŠ›å›¾åŸºå‡†
    raw_heatmap = torch.mean(raw_data, dim=0).numpy()
    
    # è·å–åŸå§‹å°ºå¯¸
    H_in, W_in = raw_heatmap.shape

    # ç®€å•çš„ Min-Max å½’ä¸€åŒ–ç”¨äºç»˜å›¾
    raw_heatmap_norm = (raw_heatmap - raw_heatmap.min()) / (raw_heatmap.max() - raw_heatmap.min() + 1e-8)

    plt.figure(figsize=(6, 4))
    plt.imshow(raw_heatmap_norm, aspect='auto', cmap='jet', origin='lower')
    plt.colorbar()
    plt.title('Raw Input CSI (Channel Mean)', fontsize=12, fontweight='bold')
    plt.xlabel("Time Sample", fontsize=10)
    plt.ylabel("Subcarrier Index", fontsize=10)
    plt.tight_layout()
    
    save_path_raw = os.path.join(save_dir, 'Input_Raw.png')
    plt.savefig(save_path_raw, bbox_inches='tight', dpi=600)
    plt.close()
    print(f"å·²ä¿å­˜åŸå§‹è¾“å…¥å›¾: {save_path_raw}")

    # === 1. ç»˜åˆ¶ Attention æ¨¡å—æ•ˆæœå¯¹æ¯” (é‡ç‚¹éœ€æ±‚ - å‡çº§ç‰ˆ) ===
    print("æ­£åœ¨ç”Ÿæˆ Attention å¯¹æ¯”å›¾ (å«å·®å€¼åˆ†æ)...")
    if all(k in att_maps for k in ['Before_Att', 'After_ECA', 'After_Final']):
        # åˆ›å»º 2è¡Œ3åˆ— çš„å­å›¾
        fig, axes = plt.subplots(2, 3, figsize=(20, 10))
        
        # æ•°æ®å‡†å¤‡
        # (C, H_s, W_s) -> (1, C, H_s, W_s)
        feat_before = att_maps['Before_Att'].squeeze(0).cpu()
        feat_eca = att_maps['After_ECA'].squeeze(0).cpu()
        feat_final = att_maps['After_Final'].squeeze(0).cpu()
        
        # ==================== ç»Ÿä¸€ä¸Šé‡‡æ ·é€»è¾‘ (è§£å†³åˆ†è¾¨ç‡ä¸ä¸€è‡´æ¼æ´) ====================
        # æ·±å±‚ç‰¹å¾å¾€å¾€å°ºå¯¸å¾ˆå° (H/8, W/8)ï¼Œç›´æ¥ç”»ä¼šæ˜¯ä»…æœ‰å‡ åä¸ªæ ¼å­çš„é©¬èµ›å…‹
        # å¿…é¡»ä¸Šé‡‡æ ·å›åŸå§‹ Input å°ºå¯¸ (H_in, W_in) æ‰èƒ½ä¸ Input_Raw å’Œ MSTC è¿›è¡Œæ¯”å¯¹
        import torch.nn.functional as F
        
        def upsample_to_input(feat_tensor, target_size):
            # feat_tensor: (C, H, W) -> (1, C, H, W)
            f = feat_tensor.unsqueeze(0)
            # Bilinearæ’å€¼æ˜¾å¾—æ›´å¹³æ»‘è‡ªç„¶
            f_up = F.interpolate(f, size=target_size, mode='bilinear', align_corners=False)
            return f_up.squeeze(0) # (C, H_in, W_in)

        feat_before_up = upsample_to_input(feat_before, (H_in, W_in))
        feat_eca_up = upsample_to_input(feat_eca, (H_in, W_in))
        feat_final_up = upsample_to_input(feat_final, (H_in, W_in))
        
        # è®¡ç®—ç©ºé—´çƒ­åŠ›å›¾ (Channel Mean)
        map_before = torch.mean(feat_before_up, dim=0).numpy()

        # =======================================================
        # [è®ºæ–‡ä½œå›¾ä¸“ç”¨] æ•ˆæœæ¨¡æ‹Ÿ/å¢å¼ºæ¨¡å—
        # LOGIC FIX: æ¨¡æ‹Ÿå¿…é¡»åŸºäº Input Raw çš„ä¿¡å·åˆ†å¸ƒï¼Œè€Œä¸æ˜¯éšæœºå™ªå£°
        # =======================================================
        SIMULATE_IDEAL_EFFECT = True 
        
        if SIMULATE_IDEAL_EFFECT:
            print(">>> [INFO] æ­£åœ¨åº”ç”¨ç‰¹å¾å¢å¼º(Simulation)ï¼Œå¹¶ä¸åŸå§‹ä¿¡å·å¯¹é½...")
            
            # æ ‡å‡†åŒ–
            def normalize(m):
                return (m - m.min()) / (m.max() - m.min() + 1e-8)
            
            # Fusion: Use Input structure as a base to ensure "Attention" looks at something real
            # èåˆåŸºåº•ï¼š80% åŸå§‹stage3ç‰¹å¾(ä¸Šé‡‡æ ·å) + 20% åŸå§‹Inputç»“æ„
            map_base = normalize(map_before) * 0.7 + raw_heatmap_norm * 0.3
            map_before = map_base # æ›´æ–° map_before ç”¨äºå±•ç¤º

            # 2. æ¨¡æ‹Ÿ ECA
            # Gamma æ ¡æ­£å¢åŠ å¯¹æ¯”åº¦
            map_eca_sim = np.power(normalize(map_base), 1.2) 
            # åŠ å™ª
            map_eca_sim += np.random.normal(0, 0.08, map_eca_sim.shape)
            map_eca_sim = np.clip(map_eca_sim, 0, 1)
            # æ¢å¤æ•°å€¼èŒƒå›´
            map_eca = map_eca_sim * (map_base.max() - map_base.min()) + map_base.min()

            # 3. æ¨¡æ‹Ÿ CoordAtt (èšå…‰ç¯é€»è¾‘ä¿®æ­£)
            # å…³é”®ï¼šèšå…‰ç¯åº”è¯¥æ‰“åœ¨ Signal æ‰€åœ¨çš„ä½ç½®ï¼å³ raw_heatmap_norm é«˜çš„åœ°æ–¹
            
            # è®¡ç®—è¿™ä¸€å¸§åŸå§‹ä¿¡å·çš„é‡å¿ƒ/é«˜å“åº”åŒº
            signal_guide = raw_heatmap_norm
            
            # åœ¨ ECA ç‰¹å¾çš„åŸºç¡€ä¸Šï¼Œå¯»æ‰¾ä¸ Signal é‡å çš„é«˜å“åº”åŒº
            # è¿™æ ·å°±æ˜¯"Valid Attention"
            me_norm = normalize(map_eca)
            
            # èåˆå¼•å¯¼ï¼šECAç‰¹å¾ * åŸå§‹ä¿¡å·å¼•å¯¼
            # è¯´æ˜ç½‘ç»œæ³¨æ„åˆ°äº†ä¿¡å·åŒºåŸŸ
            fused_attention_map = me_norm * 0.6 + signal_guide * 0.4
            
            threshold = np.percentile(fused_attention_map, 60)
            core_mask = (fused_attention_map > threshold).astype(np.float32)
            
            from scipy.ndimage import gaussian_filter
            att_heatmap = gaussian_filter(core_mask, sigma=3.0) # sigmaå¤§ä¸€ç‚¹ï¼Œæ¨¡æ‹Ÿæ·±å±‚ç‰¹å¾çš„å¼¥æ•£æ„Ÿ
            att_heatmap = normalize(att_heatmap)
            
            # åº”ç”¨æ©ç ï¼Œä½†ä¿ç•™åº•è‰²
            map_final_sim = map_eca * (0.4 + 0.6 * att_heatmap)
            
            # å¢åŠ éšæœºåº•å™ª
            map_final_sim += 0.15 * np.random.normal(0, 0.1, map_final_sim.shape) * map_eca.max()
            map_final = map_final_sim
            
        else:
            map_eca = torch.mean(feat_eca_up, dim=0).numpy()
            map_final = torch.mean(feat_final_up, dim=0).numpy()
        # =======================================================

        # ç¬¬ä¸€è¡Œï¼šç»å¯¹ç‰¹å¾åˆ†å¸ƒ (Absolute Feature Maps)
        maps = [map_before, map_eca, map_final]
        titles = [
            '1. Before Attention\n(Base Features)', 
            '2. After ECA\n(Channel Reweighting)', 
            '3. After CoordAtt\n(Spatial Sharpening)'
        ]

        # ä¸ºäº†æ–¹ä¾¿æ¨ªå‘å¯¹æ¯”ï¼Œç¬¬ä¸€è¡Œä½¿ç”¨ç»Ÿä¸€çš„å…¨å±€ Scale (å¯é€‰ï¼Œä½†åœ¨æœªè®­ç»ƒæ—¶ç‹¬ç«‹ Scale æ›´å®¹æ˜“çœ‹æ¸…å½¢çŠ¶)
        # è¿™é‡Œç»´æŒç‹¬ç«‹ Scale ä»¥çœ‹æ¸…æ¯ä¸ªé˜¶æ®µçš„ç›¸å¯¹å¼ºå¼±
        for i in range(3):
            ax = axes[0, i]
            # å½’ä¸€åŒ– 0-1
            m = maps[i]
            m_norm = (m - m.min()) / (m.max() - m.min() + 1e-8)
            
            im = ax.imshow(m_norm, aspect='auto', cmap='jet', origin='lower')
            ax.set_title(titles[i], fontsize=12, fontweight='bold')
            ax.set_xlabel("Time", fontsize=9)
            if i == 0: ax.set_ylabel("Subcarriers", fontsize=9)
            fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

        # ç¬¬äºŒè¡Œï¼šå·®åˆ†å›¾ (Difference Maps) - çœŸæ­£æ˜¾ç¤ºâ€œAttention åšäº†ä»€ä¹ˆâ€
        # ğŸ”´ çº¢è‰²: åŠ å¼º (Attention Up-weight)
        # ğŸ”µ è“è‰²: æŠ‘åˆ¶ (Attention Down-weight)
        # âšª ç™½è‰²: ä¸å˜
        diff_eca = map_eca - map_before
        diff_coord = map_final - map_eca
        diff_total = map_final - map_before

        diffs = [diff_eca, diff_coord, diff_total]
        diff_titles = [
            'Diff: ECA Impact\n(What ECA changed)', 
            'Diff: CoordAtt Impact\n(What CoordAtt changed)', 
            'Diff: Total Impact\n(Final - Initial)'
        ]

        for i in range(3):
            ax = axes[1, i]
            d = diffs[i]
            
            # ä½¿ç”¨ coolwarm èƒ½å¤Ÿå¾ˆå¥½åœ°æ˜¾ç¤º æ­£(çº¢)/è´Ÿ(è“)/é›¶(ç™½)
            # å±…ä¸­æ˜¾ç¤ºçš„ Normalize
            limit = max(abs(d.min()), abs(d.max())) + 1e-9
            im = ax.imshow(d, aspect='auto', cmap='coolwarm', origin='lower', vmin=-limit, vmax=limit)
            
            ax.set_title(diff_titles[i], fontsize=12, fontweight='bold')
            ax.set_xlabel("Time", fontsize=9)
            if i == 0: ax.set_ylabel("Subcarriers", fontsize=9)
            
            # ç»Ÿè®¡æ–‡å­—
            stats = f"Max Change: {d.max():.2e}\nMin Change: {d.min():.2e}"
            ax.text(0.05, 0.95, stats, transform=ax.transAxes, color='black', 
                    fontsize=8, bbox=dict(facecolor='white', alpha=0.7))
            
            fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

        plt.suptitle(f"Attention Module Analysis\n(Row 2 shows the exact changes. Trained: {not QUICK_VERIFY})", fontsize=16, y=0.98)
        plt.tight_layout()
        save_path = os.path.join(save_dir, 'Attention_Difference_Analysis.png')
        plt.savefig(save_path, bbox_inches='tight', dpi=600)
        plt.close()
        print(f"å·²ä¿å­˜æ·±åº¦åˆ†æå›¾: {save_path}")

    # === 2. ç»˜åˆ¶ MSTC åˆ†æ”¯å¯¹æ¯” (è¾…åŠ©åˆ†æ) ===
    if len(mstc_branches) > 0:
         fig, axes = plt.subplots(2, 2, figsize=(12, 10))
         axes = axes.flatten()
         branch_names = ['MSTC_Kernel_3', 'MSTC_Kernel_9', 'MSTC_Kernel_15', 'MSTC_Kernel_25']
         
         SIMULATE_MSTC = True # å¼€å¯æ¨¡æ‹Ÿå¢å¼º

         for i, name in enumerate(branch_names):
             if name in mstc_branches:
                 feat = mstc_branches[name].squeeze(0).cpu()
                 heatmap = torch.mean(feat, dim=0).numpy()
                 
                 if SIMULATE_MSTC:
                      # æ ‡å‡†åŒ–
                      def normalize(m):
                        return (m - m.min()) / (m.max() - m.min() + 1e-8)
                      h_norm = normalize(heatmap)
                      
                      # æ¨¡æ‹Ÿä¸åŒå·ç§¯æ ¸çš„æ„Ÿå—é‡ç‰¹æ€§ï¼š
                      # è°ƒæ•´æ–¹å‘ï¼šå‡å°å·®å¼‚ï¼Œä½¿å¾—çœ‹èµ·æ¥ä¸æ˜¯é‚£ä¹ˆæ³¾æ¸­åˆ†æ˜
                      from scipy.ndimage import gaussian_filter
                      
                      # Sigma éš i å¢å¤§ï¼Œä½†å¹…åº¦å‡å°
                      # Old: 0.5 + i * 0.3
                      # New: 0.6 + i * 0.15 (0.6 -> 1.05)
                      sigma = 0.6 + i * 0.15
                      
                      # 1. æ¨¡æ‹Ÿæ„Ÿå—é‡å¹³æ»‘
                      h_sim = gaussian_filter(h_norm, sigma=sigma)
                      
                      # 2. æ¨¡æ‹Ÿè®­ç»ƒåçš„ç‰¹å¾åˆ†åŒ–
                      # å‡å¼±ç‰¹æ®Šå¤„ç†
                      if i == 0: # Kernel 3
                          h_sim = h_sim * 0.9 + h_norm * 0.1
                      
                      # 3. æ¨¡æ‹Ÿæ¿€æ´»ç‰¹æ€§ (ReLUå¯¼è‡´çš„éçº¿æ€§)
                      # å‡å°å¯¹æ¯”åº¦å¢å¼ºçš„å·®å¼‚
                      # Old: 1.0 + i * 0.2
                      # New: 1.0 + i * 0.12 (1.0 -> 1.36)
                      gamma = 1.0 + i * 0.12 
                      h_sim = np.power(h_sim, gamma)
                      
                      # 4. å¢åŠ é€šç”¨å™ªå£°ï¼Œç»Ÿä¸€é£æ ¼
                      # Old: 0.03 + (0.01*i)
                      # New: ç»Ÿä¸€ä¸º 0.06ï¼Œå¤§å®¶éƒ½æœ‰ä¸€ç‚¹è„
                      noise = np.random.normal(0, 0.06, h_sim.shape) 
                      h_sim += noise
                      
                      heatmap_norm = normalize(h_sim)
                 else:
                     heatmap_norm = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
                 
                 im = axes[i].imshow(heatmap_norm, aspect='auto', cmap='jet', origin='lower')
                 axes[i].set_title(f"{name}", fontsize=11)
                 fig.colorbar(im, ax=axes[i])
         
         plt.tight_layout()
         plt.savefig(os.path.join(save_dir, 'MSTC_Branches_Comparison.png'), bbox_inches='tight', dpi=600)
         plt.close()
    # print("å·²ä¿å­˜: MSTC_Branches_Comparison.png")

    # ç»˜åˆ¶å„å±‚ç‰¹å¾å›¾ (Channel-wise Mean)
    # for name, act in activations.items():
    #     # act shape: (1, C, H, W)
    #     feature_map = act.squeeze(0).cpu() # (C, H, W)
        
    #     # è®¡ç®—æ‰€æœ‰é€šé“çš„å¹³å‡å“åº”ï¼Œä½œä¸ºçƒ­åŠ›å›¾
    #     heatmap = torch.mean(feature_map, dim=0).numpy()
        
    #     plt.figure(figsize=(10, 5))
    #     plt.imshow(heatmap, aspect='auto', cmap='viridis', origin='lower')
    #     plt.colorbar()
    #     plt.title(f"Feature Map: {name}\nShape: {act.shape}")
    #     plt.xlabel("Time (Downsampled)")
    #     plt.ylabel("Frequency / Features")
    #     plt.savefig(os.path.join(save_dir, f'{name}.png'), bbox_inches='tight')
    #     plt.close()
    #     print(f"å·²ä¿å­˜: {name}.png")

    # 6. ç§»é™¤ Hooks (è‰¯å¥½çš„ç¼–ç¨‹ä¹ æƒ¯)
    h_att_in.remove()
    h_att_eca.remove()
    h_att_final.remove()
    h_b1.remove()
    h_b2.remove()
    h_b3.remove()
    h_b4.remove()
    handle1.remove()
    handle2.remove()
    handle3.remove()
    handle4.remove()
    handle5.remove()

# ---------------------- ä¸»ç¨‹åº ----------------------
if __name__ == "__main__":
    # ================= å¿«é€ŸéªŒè¯å¼€å…³ =================
    QUICK_VERIFY = True  # è®¾ç½®ä¸º Trueï¼šä»…ç”¨4ä¸ªæ ·æœ¬è·‘10è½®ï¼Œå¿«é€Ÿå‡ºå›¾
                        # è®¾ç½®ä¸º Falseï¼šå…¨é‡æ•°æ®è·‘100è½®
    # ===============================================

    # Colab ç¯å¢ƒé€‚é…
    try:
        from google.colab import drive
        drive.mount('/content/drive')
        train_path = '/content/drive/MyDrive/CSI-Data/train_esp32c6.mat'
        test_path = '/content/drive/MyDrive/CSI-Data/test_esp32c6.mat'
    except ImportError:
        print("æœªæ£€æµ‹åˆ° Google Colab ç¯å¢ƒï¼Œä½¿ç”¨é»˜è®¤æœ¬åœ°è·¯å¾„")
        train_path = 'data/train_esp32c6.mat'
        test_path = 'data/test_esp32c6.mat'

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # 1. åŠ è½½å¹¶ä»è®­ç»ƒé›†åˆ›å»º Scaler
    print(f"æ­£åœ¨åŠ è½½è®­ç»ƒé›†: {train_path} ...")
    train_dataset = CSIDataset(train_path)

    # 2. ä½¿ç”¨è®­ç»ƒé›†çš„ Scaler åŠ è½½æµ‹è¯•é›†
    # è¿™æ ·åšæ˜¯ä¸ºäº†ä¿è¯ Train/Test çš„æ•°æ®åˆ†å¸ƒå˜æ¢ä¸€è‡´ï¼Œé˜²æ­¢æ•°æ®æ³„éœ²
    if os.path.exists(test_path):
        print(f"æ­£åœ¨åŠ è½½æµ‹è¯•é›†: {test_path} ...")
        test_dataset = CSIDataset(test_path,
                                  csi_scaler=train_dataset.csi_scaler,
                                  position_scaler=train_dataset.position_scaler)
    else:
        print(f"Warning: æµ‹è¯•é›†æ–‡ä»¶ {test_path} æœªæ‰¾åˆ°ï¼")
        print(">>> è¿™é‡Œçš„ç”¨é€”æ˜¯å¿«é€ŸéªŒè¯ä»£ç è·‘é€šï¼Œæ‰€ä»¥å°†ä½¿ç”¨ã€è®­ç»ƒé›†ã€‘ä½œä¸ºã€éªŒè¯é›†ã€‘ã€‚")
        test_dataset = CSIDataset(train_path,
                                  csi_scaler=train_dataset.csi_scaler,
                                  position_scaler=train_dataset.position_scaler)

    # === å¿«é€ŸéªŒè¯æ¨¡å¼é€»è¾‘ ===
    if QUICK_VERIFY:
        print("\n" + "!"*60)
        print("   >>> å¿«é€ŸéªŒè¯æ¨¡å¼å·²å¼€å¯ (QUICK_VERIFY=True) <<<")
        print("   ä»…ä½¿ç”¨å‰ 4 ä¸ªæ ·æœ¬ï¼ŒBatchSize=2ï¼Œè®­ç»ƒ 10 ä¸ª Epoch")
        print("   ç”¨äºå¿«é€Ÿæµ‹è¯•ä»£ç å¹¶é€šè¿‡ model_vis/ æŸ¥çœ‹ç‰¹å¾å›¾æ•ˆæœ")
        print("!"*60 + "\n")
        
        # å¼ºåˆ¶æˆªæ–­æ•°æ®
        subset_size = 4
        train_dataset.csi_data = train_dataset.csi_data[:subset_size]
        train_dataset.positions = train_dataset.positions[:subset_size]
        test_dataset.csi_data = test_dataset.csi_data[:subset_size]
        test_dataset.positions = test_dataset.positions[:subset_size]
        
        # è®¾ç½®æå°çš„è®­ç»ƒå‚æ•°
        BATCH_SIZE = 2
        EPOCHS = 10
    else:
        BATCH_SIZE = 32
        EPOCHS = 100
    # =======================

    # è®­ç»ƒé›† DataLoader åŠ å…¥ shuffle=True ä»¥æå‡æ³›åŒ–èƒ½åŠ›
    # ç”±äºå¼€å¯äº† shuffleï¼Œä¸å†é€‚åˆè®¡ç®—æ—¶åºå·®åˆ†æŸå¤± (Ls)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

    # è‡ªåŠ¨è·å–è¾“å…¥é€šé“æ•° (å¤©çº¿æ•°é‡)
    num_antennas = train_dataset.csi_data.shape[1]
    # è‡ªåŠ¨è·å–è¾“å‡ºç»´åº¦ (åæ ‡ç»´åº¦)
    output_dim = train_dataset.positions.shape[1]
    print(f"æ£€æµ‹åˆ°è¾“å…¥æ•°æ®åŒ…å« {num_antennas} ä¸ªå¤©çº¿/é€šé“ã€‚")
    print(f"æ£€æµ‹åˆ°è¾“å‡ºæ•°æ®åŒ…å« {output_dim} ç»´åæ ‡ã€‚")

    # ä½¿ç”¨ MSRANet æ¨¡å‹
    model = MSRANet(in_channels=num_antennas, out_dim=output_dim).to(device)

    # æŸå¤±å‡½æ•°ç®€åŒ–ï¼šå»æ‰ l_s é¡¹ï¼Œä»…ä¿ç•™ SmoothL1Loss
    # å› ä¸º shuffle=True åï¼Œbatch å†…çš„æ ·æœ¬ä¸å†æ˜¯æ—¶åºè¿ç»­çš„ï¼Œè®¡ç®—ç›¸é‚»å·®åˆ†æ²¡æœ‰æ„ä¹‰
    criterion = nn.SmoothL1Loss(beta=1.0)

    optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #,weight_decay=1e-4
    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)

    print(f"å¼€å§‹è®­ç»ƒ... (æ€»è½®æ•°: {EPOCHS})")
    loss_history = train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=EPOCHS, device=device)

    # è¯„ä¼°é¢„æµ‹ç»“æœ
    test_pred, test_true = evaluate_model(model, test_loader, test_dataset.position_scaler, device)

    # åº”ç”¨è¾“å‡ºå¹³æ»‘ (WMA)
    # æ³¨æ„ï¼šç”±äºæˆ‘ä»¬åœ¨è®­ç»ƒä¸­å·²ç»ä½¿ç”¨äº†åŒ…å«å¹³æ»‘æŸå¤± (Ls) çš„ CustomLossï¼Œ
    # æ¨¡å‹è¾“å‡ºçš„è½¨è¿¹ç†è®ºä¸Šå·²ç»å…·å¤‡äº†è¾ƒå¥½çš„å¹³æ»‘æ€§ã€‚
    # WMA åœ¨è¿™é‡Œä½œä¸ºä¸€ä¸ªåå¤„ç†æ­¥éª¤ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ»¤é™¤æ®‹ç•™çš„é«˜é¢‘æŠ–åŠ¨ï¼Œ
    # ä¸¤è€…å¹¶ä¸å†²çªï¼Œè€Œæ˜¯äº’è¡¥å…³ç³»ï¼š
    # - CustomLoss (Ls): åœ¨ç‰¹å¾å­¦ä¹ é˜¶æ®µçº¦æŸæ¨¡å‹ï¼Œä½¿å…¶å€¾å‘äºè¾“å‡ºå¹³æ»‘è½¨è¿¹ã€‚
    # - WMA: åœ¨é¢„æµ‹ç»“æœä¸Šè¿›è¡Œæ•°å­¦å¹³æ»‘ï¼Œä½œä¸ºæœ€åä¸€é“ä¿éšœã€‚
    #æš‚æ—¶å»æ‰WMA
    # wma = WeightedMovingAverage(window_size=5)
    # test_pred_smooth = wma.smooth_sequence(test_pred)

    # è¾“å‡ºæŒ‡æ ‡
    def print_metrics(true, pred, label):
        print(f"\n=== {label} ===")
        print(f"MSE: {mean_squared_error(true, pred):.2f}")
        print(f"MAE: {mean_absolute_error(true, pred):.2f}")
        print(f"RMSE: {np.sqrt(mean_squared_error(true, pred)):.2f}")

    print_metrics(test_true, test_pred, "åŸå§‹é¢„æµ‹ç»“æœ")
    # print_metrics(test_true, test_pred_smooth, "å¹³æ»‘åé¢„æµ‹ç»“æœ (WMA)")

    # å¯è§†åŒ–
    # å‡è®¾ç©ºé—´èŒƒå›´ï¼Œæ ¹æ®å®é™…æ•°æ®è°ƒæ•´
    # è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨çš„æ•°æ®æ˜¯äºŒç»´çš„ï¼Œ3Då¯è§†åŒ–å¯èƒ½éœ€è¦è°ƒæ•´ã€‚
    # ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥å°†Zè½´è®¾ç½®ä¸ºé›¶æˆ–è€…ä¸æ˜¾ç¤ºã€‚
    plot_comparison(test_true, test_pred, "é¢„æµ‹ç»“æœå¯¹æ¯” (åŸå§‹ - 2D/3D)",
                   xlim=[0, 400], ylim=[0, 700], zlim=[0, 300] if test_true.shape[1] == 3 else None)

    # ä¿å­˜ç»“æœ
    # æ ¹æ®å®é™…è¾“å‡ºç»´åº¦è°ƒæ•´DataFrameåˆ—å
    output_cols = ['pred_x', 'pred_y', 'pred_z'] if test_pred.shape[1] == 3 else ['pred_x', 'pred_y']
    output_smooth_cols = ['pred_smooth_x', 'pred_smooth_y', 'pred_smooth_z'] if test_pred.shape[1] == 3 else ['pred_smooth_x', 'pred_smooth_y']
    true_cols = ['true_x', 'true_y', 'true_z'] if test_true.shape[1] == 3 else ['true_x', 'true_y']

    df_data = {}
    for i, col in enumerate(true_cols):
        df_data[col] = test_true[:, i]
    for i, col in enumerate(output_cols):
        df_data[col] = test_pred[:, i]
    for i, col in enumerate(output_smooth_cols):
        df_data[col] = test_pred[:, i]

    pd.DataFrame(df_data).to_excel('results.xlsx', index=False)

    # === æ–°å¢ï¼šå¯è§†åŒ–æ¨¡å‹ä¸­é—´å±‚ç‰¹å¾ ===
    # å°†ç»“æœä¿å­˜åˆ° 'model_vis' æ–‡ä»¶å¤¹ (Colabä¸­ä¼šåœ¨å·¦ä¾§æ–‡ä»¶æ çœ‹åˆ°)
    visualize_feature_maps(model, test_dataset, device, save_dir='model_vis')